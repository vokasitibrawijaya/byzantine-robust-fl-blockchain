# Byzantine-Robust Federated Learning with Blockchain

[![Paper](https://img.shields.io/badge/Paper-IEEE%20Access-blue)](https://doi.org/10.1109/ACCESS.2026.XXXXXXX)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.10+-yellow.svg)](https://python.org)

## Paper Supplementary Materials

This repository contains the experimental code, results, and artifacts for:

**"Byzantine-Robust Federated Learning with Adaptive Aggregation and Blockchain: Empirical Validation and Resolution of the Transparency Paradox"**

*Submitted to IEEE Access (Major Revision)*

---

## ğŸ“ Repository Structure

```
â”œâ”€â”€ src/                              # Source code
â”‚   â”œâ”€â”€ aggregation/                  # Aggregation algorithms (ATMA, TrimmedMean, Krum, etc.)
â”‚   â”œâ”€â”€ experiments/                  # Main experiment scripts
â”‚   â”‚   â”œâ”€â”€ h2_valid_rerun.py        # H2: ROC/AUC provenance detection
â”‚   â”‚   â”œâ”€â”€ real_fl_training_FIXED.py # Real FL training on MNIST
â”‚   â”‚   â”œâ”€â”€ run_cifar10_blockchain_simple.py  # CIFAR-10 experiments
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ blockchain/                   # Smart contracts & blockchain integration
â”‚   â””â”€â”€ utils/                        # Utility functions
â”œâ”€â”€ results/                          # Experiment results (JSON)
â”‚   â”œâ”€â”€ h2_valid_rerun_results.json   # Table II, Figure 2
â”‚   â”œâ”€â”€ real_fl_training_FIXED.json   # Table VI
â”‚   â”œâ”€â”€ cifar10_blockchain_simple_*.json  # Table XII
â”‚   â”œâ”€â”€ multiseed_comparison_*.json   # Table XIII
â”‚   â””â”€â”€ blockchain_cost_benefit_analysis.json  # Table XIV
â”œâ”€â”€ visualizations/                   # Generated figures
â”œâ”€â”€ ACCESS_latex_template_20240429/   # Paper LaTeX source
â”œâ”€â”€ ARTIFACT_MANIFEST.md              # Detailed artifact documentation
â””â”€â”€ MAJOR_REVISION_RESPONSE.md        # Revision changelog
```

---

## ğŸ“Š Key Results Summary

### CIFAR-10 Validation (Dirichlet Î±=0.5, 20% Byzantine)

| Method | 50 Rounds | 160 Rounds | Status |
|--------|-----------|------------|--------|
| **TrimmedMean** | 66.38% | **67.92%** | Best |
| ATMA | 64.38% | 65.78% | Competitive |
| Krum | 36.71% | 43.41% | Moderate |
| FedAvg | 10.0% | 10.0% | Collapsed |
| FedProx | 10.0% | 10.0% | Not Byzantine-robust |
| FedDyn | 10.0% | 10.0% | Not Byzantine-robust |

### Provenance Detection (H2)

| Metric | Blockchain | Centralized |
|--------|------------|-------------|
| **AUC** | **0.957** | 0.000 |
| TPR | 81.0% | 0% |
| FPR | 0.0% | 0% |

### Real FL on MNIST (20 rounds, seeds 42-44)

| Method | Accuracy |
|--------|----------|
| TrimmedMean | 73.00% Â± 3.39% |
| Median | 71.48% Â± 4.52% |
| Mean | 66.95% Â± 3.55% |

---

## ğŸ”§ Installation

```bash
# Clone repository
git clone https://github.com/tivokasibrawijaya/byzantine-robust-fl-blockchain.git
cd byzantine-robust-fl-blockchain

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Install dependencies
pip install torch torchvision numpy scikit-learn web3 matplotlib
```

---

## ğŸš€ Running Experiments

### H2: Provenance Detection (ROC/AUC)
```bash
python src/experiments/h2_valid_rerun.py
# Output: results/h2_valid_rerun_results.json
```

### Real FL Training on MNIST
```bash
python src/experiments/real_fl_training_FIXED.py
# Output: results/real_fl_training_FIXED.json
```

### CIFAR-10 with Byzantine Attacks
```bash
python src/experiments/run_cifar10_blockchain_simple.py
# Output: results/cifar10_blockchain_simple_*.json
```

### Multi-seed Confidence Intervals
```bash
python src/experiments/quick_multiseed_fedprox_feddyn.py
# Output: results/multiseed_comparison_*.json
```

---

## ğŸ“‹ Experiment Configuration

| Experiment | Dataset | Attack | Byzantine | Rounds | Seeds |
|------------|---------|--------|-----------|--------|-------|
| Table II | MNIST | Tamper | 30% prob | 50 | 42 |
| Table VI | MNIST | Sign-flip | 4/20 | 20 | 42,43,44 |
| Table XII | CIFAR-10 | Label-flip(Î»=-5) | 4/20 | 50-160 | 42 |
| Table XIII | CIFAR-10 | Label-flip(Î»=-5) | 4/20 | 50 | 42,43,44 |

**Note:** Table XIII uses reduced hyperparameters (epochs=3, batch=256) for rapid multi-seed evaluation, explaining the 34.62% vs 66.38% accuracy difference from Table XII.

---

## ğŸ“„ Citation

```bibtex
@article{author2026byzantine,
  title={Byzantine-Robust Federated Learning with Adaptive Aggregation and Blockchain},
  author={[Author Names Withheld for Blind Review]},
  journal={IEEE Access},
  year={2026},
  note={Under Review}
}
```

---

## ğŸ“ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ”— Related Resources

- [ARTIFACT_MANIFEST.md](ARTIFACT_MANIFEST.md) - Detailed mapping of paper tables to result files
- [MAJOR_REVISION_RESPONSE.md](MAJOR_REVISION_RESPONSE.md) - Complete revision changelog

---

*Last Updated: January 4, 2026*
